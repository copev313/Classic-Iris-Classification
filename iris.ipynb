{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('env': venv)"
    },
    "interpreter": {
      "hash": "3bb249a9bc2daac80aaa1d0eaced1fd33ec4c00214ecb795603296da235714ce"
    },
    "colab": {
      "name": "iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/copev313/Classic-Iris-Classification/blob/main/iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR3xdGYklRzI"
      },
      "source": [
        "# Iris Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8HebL-qlRzK"
      },
      "source": [
        "We will be using the Iris dataset provided with `scikit-learn` to build a model for predicting the species of iris flowers. Although the Iris is a genus of 260-300 species, we will only be covering the **Setosa**, **Versicolor**, and **Virginica** species in this demonstration.\n",
        "\n",
        "Each sample in our dataset has the length and widths of the sepal and petal of each flower (*our features*). It also has the species of the flower (*the target*). Our goal is to be able to identify the species of a plant given its sepal and petal measurements. This is a supervised learning problem given our targets are provided with the data, and a classification problem provided we have a finite number of species as a solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW5uvOoalRzL"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMPWkq4sl97b"
      },
      "source": [
        "!pip install scikit-learn pandas --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_v8oTdrlRzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d710697d-048d-4629-fc8e-65929aa308fb"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# See the attributes of our dataset:\n",
        "dir(iris)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd7MvbfglRzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d916e3b-dc2b-4a4c-b32e-59e5e4f8949c"
      },
      "source": [
        "# See the description of each attribute:\n",
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpzCKtclRzO"
      },
      "source": [
        "Note that our data is made up of 150 samples, which is relative small for a classification problem. On the other hand, the data is perfectly balanced with 50 samples from each class, which plays in our favor.\n",
        "\n",
        "Our four features include: **_sepal length_**, **_sepal width_**, **_petal length_**, and **_petal width_**. All of these are numeric with no missing values.\n",
        "\n",
        "According to our summary statistics, the dataset has a strong correction between petal dimensions and class values. Normally we would only want to calculate summary statistics on the training data, leaving the rest free in the wild to test the model later. However, we will ignore this information for the sake of this example. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eP43notlRzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d12ecbe-4002-458f-d965-f66c52383c73"
      },
      "source": [
        "# See the name of our features:\n",
        "print('Features: \\n', iris.feature_names, '\\n')\n",
        "\n",
        "# See the first ten samples:\n",
        "print('Samples: \\n', iris.data[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: \n",
            " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
            "\n",
            "Samples: \n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YwD-1zYlRzP"
      },
      "source": [
        "Our target variable has three possible values: 0 for **Iris-Setosa**, 1 for **Iris-Versicolor**, and 2 for **Iris-Virginica**.\n",
        "\n",
        "Now that we know more about the data we are dealing with, let's load it into a `pandas` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWGLPzzlRzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "e3e3618b-26c7-4415-81fc-1930300b8b60"
      },
      "source": [
        "# Load data into DataFrame:\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add out 'target' column:\n",
        "df['target'] = pd.Series(iris.target)\n",
        "\n",
        "# Map our numerical target values to the class names:\n",
        "df['target_name'] = df['target'].apply(lambda y: iris.target_names[y])\n",
        "\n",
        "# See a sample:\n",
        "df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "      <th>target_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>6.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  ...  target  target_name\n",
              "112                6.8               3.0  ...       2    virginica\n",
              "115                6.4               3.2  ...       2    virginica\n",
              "85                 6.0               3.4  ...       1   versicolor\n",
              "60                 5.0               2.0  ...       1   versicolor\n",
              "38                 4.4               3.0  ...       0       setosa\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgpY2bMlRzR"
      },
      "source": [
        "The `sample` method will return a random sample of n rows from the dataset. This means we will get a random subset each time we run the code. To alleviate this, we can supply a seed value by setting the `random_state` parameter. \n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvBke9P0lRzS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "2380b7ce-1848-4ad5-b3b6-8df824191c36"
      },
      "source": [
        "df.sample(n=5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "      <th>target_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.6</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>6.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  ...  target  target_name\n",
              "73                 6.1               2.8  ...       1   versicolor\n",
              "18                 5.7               3.8  ...       0       setosa\n",
              "118                7.7               2.6  ...       2    virginica\n",
              "78                 6.0               2.9  ...       1   versicolor\n",
              "76                 6.8               2.8  ...       1   versicolor\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Q0y31FlRzS"
      },
      "source": [
        "## Spitting the Data into Training and Test Sets\n",
        "\n",
        "Now it's time to divide our DataFrame into a training set and a test set. We'll use 70% of the data for training and the other 30% for testing our model later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31M5SvpXlRzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcf8fa9-4722-4832-daf0-3ec7fc3eb814"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split our samples:\n",
        "df_train, df_test = train_test_split(df, test_size=0.3)\n",
        "\n",
        "# Check the size of our training and test sets:\n",
        "print('Training dataset entries: ', df_train.shape[0])\n",
        "print('Testing dataset entries: ', df_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset entries:  105\n",
            "Testing dataset entries:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1khrxty_lRzT"
      },
      "source": [
        "Now we will define our x and y variables, for our features and target variable respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xm_56nLlRzT"
      },
      "source": [
        "# Training set:\n",
        "x_train = df_train[iris.feature_names]\n",
        "y_train = df_train['target']\n",
        "\n",
        "# Testing set:\n",
        "x_test = df_test[iris.feature_names]\n",
        "y_test = df_test['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-HoEFjilRzU"
      },
      "source": [
        "## Training Our Model & Generating Predictions\n",
        "\n",
        "For simplicity we will use the default configuration of the `DecisionTreeClassifier` class as our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBliCbcAlRzU"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Fitting the model:\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set:\n",
        "y_test_pred = classifier.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B79U0arUlRzU"
      },
      "source": [
        "# Evaluating Our Model\n",
        "\n",
        "Now compare our *y_test_pred* to our *y_test* to see how accurate our model is. Provided our dataset is perfectly balanced (as all things should be :) ), it will be best to use the `accuracy` metric here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aLarOwxlRzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037f445b-e960-460b-d75e-0c13eeed2ef5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(\n",
        "    round(accuracy_score(y_test, y_test_pred), 5)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.93333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klrFT38elRzU"
      },
      "source": [
        "We've just trained our supervised learning model! Now we can take a closer look to see which features were most important in deciding our iris species. \n",
        "\n",
        "We will use the `feature_importances_` method of the `DecisionTreeClassifer` to see which features were most useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGGCiHeLlRzV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "9a30e3a1-3bd8-4981-b4a6-5afd8ae3ea20"
      },
      "source": [
        "pd.DataFrame(\n",
        "    { 'feature_names': iris.feature_names,\n",
        "      'feature_importance': classifier.feature_importances_,\n",
        "     }\n",
        "  \n",
        ").sort_values(by='feature_importance', ascending=False\n",
        "              \n",
        ").set_index('feature_names')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_importance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_names</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>petal length (cm)</th>\n",
              "      <td>0.564097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>petal width (cm)</th>\n",
              "      <td>0.416819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <td>0.019084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   feature_importance\n",
              "feature_names                        \n",
              "petal length (cm)            0.564097\n",
              "petal width (cm)             0.416819\n",
              "sepal width (cm)             0.019084\n",
              "sepal length (cm)            0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r-Q7QO0lRzV"
      },
      "source": [
        "These results confirm the dataset descriptions displayed earlier which stated petal and and width were highly correlated to our target variable.\n",
        "\n",
        "We can print the internal structure of our learning tree to see how the tree was built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy_XB20xlRzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1554d313-3c85-4cd3-c742-3045673c0cd5"
      },
      "source": [
        "from sklearn.tree import export_text\n",
        "\n",
        "\n",
        "print(\n",
        "    export_text(\n",
        "        classifier, feature_names=iris.feature_names,\n",
        "        spacing=3, decimals=1\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|--- petal length (cm) <= 2.6\n",
            "|   |--- class: 0\n",
            "|--- petal length (cm) >  2.6\n",
            "|   |--- petal width (cm) <= 1.8\n",
            "|   |   |--- petal length (cm) <= 5.0\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- petal length (cm) >  5.0\n",
            "|   |   |   |--- petal width (cm) <= 1.6\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- petal width (cm) >  1.6\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |--- petal width (cm) >  1.8\n",
            "|   |   |--- petal length (cm) <= 4.9\n",
            "|   |   |   |--- sepal width (cm) <= 3.1\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- sepal width (cm) >  3.1\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- petal length (cm) >  4.9\n",
            "|   |   |   |--- class: 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL10kJIklRzW"
      },
      "source": [
        "# Getting the Best Model\n",
        "\n",
        "What can be done to get a more reliable score?\n",
        "\n",
        "One way is to run the process multiple times to get a distribution of different scores. Below we run through the process of splitting, training, and testing our model 100 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXlppwChlRzW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Create a list to hold our scores from each iteration:\n",
        "accuracy_scores = []\n",
        "\n",
        "for _ in range(100):\n",
        "    \n",
        "    # Split the data into a training and testing set:\n",
        "    df_train, df_test = train_test_split(df, test_size=0.3)\n",
        "\n",
        "    x_train = df_train[iris.feature_names]\n",
        "    x_test = df_test[iris.feature_names]\n",
        "\n",
        "    y_train = df_train['target']\n",
        "    y_test = df_test['target']\n",
        "\n",
        "    # Create a new classifier model:\n",
        "    clf = DecisionTreeClassifier(random_state=7)\n",
        "\n",
        "    # Training + predicting:\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    # Add the accuracy score to the list of scores:\n",
        "    accuracy_scores.append(\n",
        "        round(accuracy_score(y_test, y_pred), 3)\n",
        "    )\n",
        "\n",
        "\n",
        "# Convert the list of scores to a pandas Series:\n",
        "accuracy_scores = pd.Series(accuracy_scores)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57tv5PEolRzX"
      },
      "source": [
        "# Visualizing the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0KF4Zi8lRzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "af9fe004-1734-4432-ff94-61e96b754643"
      },
      "source": [
        "# Plot the accuracy distribution using a box plot:\n",
        "accuracy_scores.plot(\n",
        "    title='Distribution of Classifier Accuracy',\n",
        "    kind='box',\n",
        ")\n",
        "\n",
        "print(\n",
        "    'Average Score: {:.3} [5th percentile: {:.3} | 95th percentile: {:.3}]'.format(\n",
        "        accuracy_scores.mean(),\n",
        "        accuracy_scores.quantile(0.05),\n",
        "        accuracy_scores.quantile(0.95),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Score: 0.942 [5th percentile: 0.867 | 95th percentile: 0.979]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jgwf9SYlRzX"
      },
      "source": [
        "# Data Shuffling\n",
        "\n",
        "When we run different train and test splits, it results in a more reliable estimation when it comes to the accuracy of our model.\n",
        "\n",
        "The `ShuffleSplit` modules allows us to take advantage of Monte Carlo cross validation. This method will provide a list of indices that can used for splitting our data. To implement this, we'll have to use the `loc` method provided with DataFrames to randomly split our data set into 100 pairs of training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9wUFgpklRzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f65354c-d66c-4d9c-dc94-932ca5ee75cd"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "accuracy_scores = []\n",
        "\n",
        "# Create the ShuffleSplit instance:\n",
        "shuffle = ShuffleSplit(n_splits=100, test_size=0.3)\n",
        "\n",
        "# Generate 100 pairs of indices:\n",
        "for train_index, test_index in shuffle.split(df):\n",
        "    \n",
        "    x_train = df.loc[train_index, iris.feature_names]\n",
        "    x_test = df.loc[test_index, iris.feature_names]\n",
        "    \n",
        "    y_train = df.loc[train_index, 'target']\n",
        "    y_test = df.loc[test_index, 'target']\n",
        "    \n",
        "    clf = DecisionTreeClassifier(random_state=7)\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    \n",
        "    accuracy_scores.append(round(accuracy_score(y_test, y_pred), 3))\n",
        "\n",
        "accuracy_scores = pd.Series(accuracy_scores)\n",
        "\n",
        "# Take a look at some of the results:\n",
        "print(accuracy_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     0.933\n",
            "1     0.889\n",
            "2     0.956\n",
            "3     0.911\n",
            "4     0.911\n",
            "      ...  \n",
            "95    0.978\n",
            "96    0.956\n",
            "97    0.933\n",
            "98    0.956\n",
            "99    0.978\n",
            "Length: 100, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdEh4aF9lRzY"
      },
      "source": [
        "To simplify our work even more we can use scikit-learn's `cross_validate` functionality as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO69EmXslRzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd499eb-fd43-416a-aa14-de455d79736e"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "shuffle = ShuffleSplit(n_splits=100, test_size=0.3, random_state=7)\n",
        "\n",
        "x = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "cv_results = cross_validate(clf, x, y, cv=shuffle, scoring='accuracy')\n",
        "\n",
        "accuracy_scores = pd.Series(cv_results['test_score'])\n",
        "\n",
        "# See some results:\n",
        "print(accuracy_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     0.866667\n",
            "1     0.911111\n",
            "2     0.955556\n",
            "3     0.911111\n",
            "4     0.911111\n",
            "        ...   \n",
            "95    0.977778\n",
            "96    0.933333\n",
            "97    0.888889\n",
            "98    0.977778\n",
            "99    0.955556\n",
            "Length: 100, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpYHQVPVlRzY"
      },
      "source": [
        "Cross-validation is always a good idea, especially when you have a small dataset. Accuracy scores give a better understanding of how well our model is performing.\n",
        "\n",
        "The Iris data set provides a nice example for beginners of how well Machine Learning can make predictions with just a little tuning."
      ]
    }
  ]
}